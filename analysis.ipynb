{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa9c56fe-beab-4acf-8c0c-f8e6351379f2",
   "metadata": {},
   "source": [
    "Flavor physics analysis looking for decays of D or B mesons. In this example we run the reconstruction of Ds->phi(mumu)pi decays, looking for two collimated muons and a charged track originating from a common vertex. The analysis is performed on ntuples produced running on CMS data in the MINIAOD format."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c07bc5f-e85f-4aeb-be42-e44946b9e6e2",
   "metadata": {},
   "source": [
    "## Basic imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38baabf2-e789-4dc5-8b6b-c04034895d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os, time\n",
    "start = time.time()\n",
    "import json\n",
    "import ROOT\n",
    "from ROOT import * "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c5ce488-fcda-43d3-b8ae-51f1a545d1e6",
   "metadata": {},
   "source": [
    "## Dask scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc8d1c5-7ed2-45d3-8e7e-79c28250c79a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.distributed import Client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afbcf18e-cfa4-4116-a62b-6c8d8377bd32",
   "metadata": {},
   "source": [
    "Now start new Dask cluster, scale the number of workers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e39d408-41b5-4e5d-b4f4-602008c9600e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill this cell with \"<>\" button of Dask labextension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e47e92-99c9-400f-b47b-2b3312cf2361",
   "metadata": {},
   "outputs": [],
   "source": [
    "# alternative to previous cell\n",
    "sched_port = 20974 ## Change this from the DASK cluster information panel\n",
    "client = Client(\"localhost:\" + str(sched_port))\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d7d9b11-f070-4179-83e6-255e0901982c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#client.restart() #Execute this only to restart the workers (to relaunch the notebook, for example)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38b57024-9bae-4a13-9d34-10db23e7bf2c",
   "metadata": {},
   "source": [
    "## Declare custom C++ functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b30f77-f8a9-429d-9087-d6e4fa54d465",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_file = open(\"Utilities.h\", \"r\")\n",
    "data = text_file.read()\n",
    "\n",
    "\n",
    "def my_initialization_function():\n",
    "    ROOT.gInterpreter.Declare('{}'.format(data))\n",
    "\n",
    "ROOT.RDF.Experimental.Distributed.initialize(my_initialization_function)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f24a4bc-57ec-46c2-a00a-36d47b73e455",
   "metadata": {},
   "source": [
    "## X509 proxy configuration\n",
    "The `/tmp/x509up_u` file should be generated prior running the notebook using `voms-proxy-init `"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f97df9-36da-4eef-972c-8c6e62be5aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from distributed.diagnostics.plugin import UploadFile\n",
    "client.register_worker_plugin(UploadFile(\"/tmp/x509up_u0\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1c0443d-2d68-4c2a-8258-5eae5768d262",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_proxy(dask_worker):\n",
    "    import os\n",
    "    import shutil\n",
    "    working_dir = dask_worker.local_directory\n",
    "    proxy_name = 'x509up_u0'\n",
    "    os.environ['X509_USER_PROXY'] = working_dir + '/' + proxy_name\n",
    "    os.environ['X509_CERT_DIR']=\"/cvmfs/grid.cern.ch/etc/grid-security/certificates/\"\n",
    "    return os.environ.get(\"X509_USER_PROXY\"), os.environ.get(\"X509_CERT_DIR\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f6eaa44-877a-4093-9f6c-8c0f9102c953",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.run(set_proxy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "083b987b-43aa-446a-a15f-a4dba64bdfd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading PROXY locally\n",
    "os.environ['X509_USER_PROXY'] = \"/tmp/x509up_u0\"\n",
    "os.environ['X509_CERT_DIR'] = \"/cvmfs/grid.cern.ch/etc/grid-security/certificates/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "070ce353-2278-4a01-83e2-a7087e1476c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_nodes(dask_worker):\n",
    "    import os\n",
    "    os.popen('rm ./*.root')\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab7b3ef8-884e-4f15-910b-350727438b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.run(clear_nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b45f1e4-793b-43b6-8b27-32eb3e9dda54",
   "metadata": {},
   "source": [
    "Configuration files or additional input files (i.e. scale factors, PU reweighting) should be pushed to the worker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eacac2b-8b59-424b-b1ec-1b5cefeb815b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#myfile = localpath/tomyfile\n",
    "#client.register_worker_plugin(UploadFile(config[myfile]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9f30f7c-bdec-4c0d-83fe-37b8427a8a2b",
   "metadata": {},
   "source": [
    "## Define chain of rootfiles to analyze\n",
    "ntuples corresponding to different datasets and eras are defined in a configuration json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f16b05e9-788d-4e51-9fcd-dd9f261a1118",
   "metadata": {},
   "outputs": [],
   "source": [
    "configjson = \"/opt/workspace/persistent-storage/BPH_usecase/input.json\"\n",
    "\n",
    "with open(configjson, \"r\") as f:\n",
    "    config = json.loads(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bba04b2f-4e40-4654-aab1-8495fefeb1fc",
   "metadata": {},
   "source": [
    "Set here which dataset to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7707b42-84c7-4c49-b78e-bae67ea53604",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"2018A\"\n",
    "\n",
    "path = \"xroot://xr-4-4-9-3.recas.ba.infn.it:8080/\"+config[dataset][\"rootpath\"]\n",
    "print(path)\n",
    "treename = config[dataset][\"treename\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a957c3-dfe5-4e63-b053-c048f55312d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#generating the list of all .root files in given directory and subdirectories\n",
    "chain = []\n",
    "for r, d, f in os.walk(path): # r=root, d=directories, f = files\n",
    "    for file in f:\n",
    "        if '.root' in file:\n",
    "            chain.append(os.path.join(r, file))\n",
    "\n",
    "print(chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e48a38fb-5586-4499-bc30-23fae92c9243",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = ROOT.RDataFrame(treename, \"/opt/workspace/persistent-storage/BPH_usecase/Tree_PhiPi_1-1.root\") #not distributed\n",
    "\n",
    "numWorkers= len(client.scheduler_info()['workers'])\n",
    "npartitions = 3 * numWorkers\n",
    "\n",
    "print(\"Number of workers is: {}\".format(numWorkers))\n",
    "print(\"Number of total partitions is: {}\".format(npartitions))\n",
    "\n",
    "#df = ROOT.RDF.Experimental.Distributed.Dask.RDataFrame(treename, chain, npartitions=npartitions, daskclient=client)   \n",
    "df = ROOT.RDF.Experimental.Distributed.Dask.RDataFrame(treename, \"/opt/workspace/persistent-storage/BPH_usecase/Tree_PhiPi_1-1.root\", npartitions=npartitions, daskclient=client)   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8b1844f-c87c-45eb-9676-fe1f39c0b1e2",
   "metadata": {},
   "source": [
    "# DsPhiPi Analysis cutflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ec9ae6-8c9f-4716-b01a-e10aad5f08a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 -> Event fires L1 and HLT\n",
    "\n",
    "df = df.Define(\"HLT_mask\", \"Trigger_hltdecision==1 && contains(Trigger_hltname,\\\"HLT_DoubleMu3_Trk_Tau3mu_v\\\")\").Filter(\"ROOT::VecOps::Sum(HLT_mask) >0\")\n",
    "df = df.Define(\"L1_mask\", \"Trigger_l1decision==1 && ( contains(Trigger_l1name,\\\"L1_DoubleMu\\\") || contains(Trigger_l1name,\\\"L1_TripleMu\\\"))\").Filter(\"ROOT::VecOps::Sum(L1_mask) >0\")\n",
    "\n",
    "# Selections on triplets\n",
    "# 2 -> 2mu+track candidate mass in (1.62-2.02)GeV\n",
    "# 3 -> at least 2 track associated with PV\n",
    "# 4 -> Significance of BS-SV distance in the transverse plane > 2\n",
    "triplet_selection = \"Triplet2_Mass>1.62 && Triplet2_Mass<2.02 && \\\n",
    "                     RefittedPV2_NTracks > 1 && \\\n",
    "                     FlightDistBS_SV_Significance > 2 \"\n",
    "\n",
    "# Events with at least one good candidate\n",
    "df = df.Define(\"triplet_mask1\", triplet_selection).Filter(\"ROOT::VecOps::Sum(triplet_mask1) >0\")\n",
    "\n",
    "# 5 -> Muons and track within CMS acceptance\n",
    "acceptance_selection = \"((abs(Mu01_Eta)<1.2 && Mu01_Pt>3.5) || (abs(Mu01_Eta)>=1.2 && abs(Mu01_Eta)<2.4 && Mu01_Pt>2.0)) &&\\\n",
    "                        ((abs(Mu02_Eta)<1.2 && Mu02_Pt>3.5) || (abs(Mu02_Eta)>=1.2 && abs(Mu02_Eta)<2.4 && Mu02_Pt>2.0)) &&\\\n",
    "                        Tr_Pt>1.2\"\n",
    "# Events with at least one good candidate\n",
    "df = df.Define(\"triplet_mask2\", acceptance_selection).Filter(\"ROOT::VecOps::Sum(triplet_mask2)>0\")\n",
    "\n",
    "# Compute dR and dZ between muons/tracks\n",
    "df = df.Define(\"dR12\", \"deltaR_vec(Mu01_Eta, Mu02_Eta, Mu01_Phi, Mu02_Phi)\")\n",
    "df = df.Define(\"dR13\", \"deltaR_vec(Mu01_Eta, Tr_Eta, Mu01_Phi, Tr_Phi)\")\n",
    "df = df.Define(\"dR23\", \"deltaR_vec(Mu02_Eta, Tr_Eta, Mu02_Phi, Tr_Phi)\")\n",
    "\n",
    "# 6 -> min and max deltaR requirement\n",
    "dR_selection = \"dR12>DELTAR_MIN && dR13>DELTAR_MIN && dR23>DELTAR_MIN &&\\\n",
    "                dR12<DELTAR_MAX && dR13<DELTAR_MAX && dR23<DELTAR_MAX\"\n",
    "df = df.Define(\"triplet_mask3\", dR_selection).Filter(\"ROOT::VecOps::Sum(triplet_mask3)>0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a253190-56c1-4a25-bcf7-a7d8735d2efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find index in \"Muon_\" and \"Track_\" branches\n",
    "df = df.Define(\"Mu01_index\", \"match(MuonPt, Mu01_Pt)\")\n",
    "df = df.Define(\"Mu02_index\", \"match(MuonPt, Mu02_Pt)\")\n",
    "df = df.Define(\"Tr_index\",   \"match(MuonPt, Tr_Pt)\")\n",
    "\n",
    "# 7 -> Apply Muon ID Global and Particle Flow\n",
    "df = df.Define(\"Mu01_ID\", \"muon_id(Mu01_index, Muon_isGlobal && Muon_isPF)\")\n",
    "df = df.Define(\"Mu02_ID\", \"muon_id(Mu02_index, Muon_isGlobal && Muon_isPF)\")\n",
    "\n",
    "# 8 -> IP(track, BS) z direction < 20 cm and xy direction < 0.3 cm\n",
    "df = df.Define(\"Tr_IPcut\", \"muon_id(Tr_index, (Track_dz<20 && Track_dxy<0.3) )\")\n",
    "df = df.Define(\"triplet_mask4\", \"Mu01_ID && Mu02_ID && Tr_IPcut\").Filter(\"ROOT::VecOps::Sum(triplet_mask4)>0\")\n",
    "\n",
    "# 9 -> dimuon mass compatible with phi(1020) RefTrack1_Eta\n",
    "df = df.Define(\"Dimu_mass\", \"dimu_mass(RefTrack1_Pt, RefTrack1_Eta, RefTrack1_Phi, RefTrack2_Pt, RefTrack2_Eta, RefTrack2_Phi)\")\n",
    "df = df.Define(\"triplet_mask5\", \"Dimu_mass>1.0 && Dimu_mass<1.04\").Filter(\"ROOT::VecOps::Sum(triplet_mask5)>0\")\n",
    "\n",
    "# 10 -> Trigger Matching (to-do)\n",
    "\n",
    "# Keep best candidate based on vertex chi2\n",
    "df = df.Define(\"BestTriplet_index\", \"bestcandidate(TripletVtx2_Chi2)\")\n",
    "df = df.Define(\"BestTriplet_mass\", \"flattening(Triplet2_Mass, BestTriplet_index)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88707d9b-c9e7-407d-a2ca-fd3944eccec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a histogram from `x` and draw it\n",
    "h = df.Histo1D((\"h_mass\", \"h_mass\", 80, 1.65, 2.05), \"BestTriplet_mass\")\n",
    "c =  ROOT.TCanvas()\n",
    "h.Draw(\"hist\")\n",
    "c.Draw()\n",
    "# Save output for further processing\n",
    "df_out = df.Snapshot(\"ntuple\", \"out.root\", [\"BestTriplet_mass\"]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02faf2fe-c057-4bbc-838d-c923c5a49579",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fitting invariant mass :)\n",
    "from ROOT import RooRealVar\n",
    "\n",
    "x = ROOT.RooRealVar(\"BestTriplet_mass\", \"2mu+1trk inv. mass (GeV)\", 1.65, 2.05)\n",
    "x.setBins(80)\n",
    "\n",
    "# We first declare the RooDataHistHelper\n",
    "rdhMaker = ROOT.RooDataHistHelper(\"dataset\", \"Title of dataset\", ROOT.RooArgSet(x))\n",
    "\n",
    "# Then, we move it into an RDataFrame action:\n",
    "data_result = df_out.Book(ROOT.std.move(rdhMaker), (\"BestTriplet_mass\"))\n",
    "data = roo_data_hist_result.GetValue()\n",
    "entries = data.numEntries()\n",
    "\n",
    "#data = RooDataHist(\"data\", \"h_mass\", RooArgSet(x), RooFit.Import(h, ROOT.kFALSE))\n",
    "\n",
    "x.setRange(\"R1\", 1.70, 1.80)\n",
    "x.setRange(\"R2\", 1.89, 1.925)\n",
    "x.setRange(\"R3\", 1.99, 2.02)\n",
    "\n",
    "meanCB = RooRealVar(\"mean\", \"meanCB\", 1.97, 1.94, 2.1)\n",
    "sigmaCB1 = RooRealVar(\"#sigma_{CB}\", \"sigmaCB1\", 0.02, 0.001, 0.1)\n",
    "alpha1 = RooRealVar(\"#alpha1\", \"alpha1\", 1.0, 0.5, 10.0)\n",
    "nSigma1 = RooRealVar(\"n1\", \"n1\", 1.0, 0.1, 25.0)\n",
    "sig_right = RooCBShape(\"sig_right\", \"sig_right\", x, meanCB, sigmaCB1, alpha1, nSigma1)\n",
    "\n",
    "meanCB2 = RooRealVar(\"mean2\", \"meanCB2\", 1.87, 1.82, 1.89)\n",
    "sigmaCB2 = RooRealVar(\"#sigma2_{CB}\", \"sigmaCB2\", 0.05, 0.001, 0.05)\n",
    "alpha2 = RooRealVar(\"#alpha2\", \"alpha2\", 1.0, 0.5, 10.0)\n",
    "nSigma2 = RooRealVar(\"n2\", \"n2\", 1.0, 0.1, 25.0)\n",
    "sig_left = RooCBShape(\"sig_left\", \"sig_left\", x, meanCB2, sigmaCB2, alpha2, nSigma2)\n",
    "\n",
    "gamma = RooRealVar(\"#Gamma\", \"Gamma\", -1, -2.0, -1e-2)\n",
    "exp_bkg = RooExponential(\"exp_bkg\", \"exp_bkg\", x, gamma)\n",
    "exp_bkg.fitTo(data, RooFit.Range(\"R1,R2,R3\"))\n",
    "\n",
    "nSig_right = RooRealVar(\"nSig_R\", \"Number of signal candidates\", entries*0.05, 1.0, 1e+6)\n",
    "nSig_left = RooRealVar(\"nSig_L\", \"Number of signal 2 candidates\", entries*0.02, 1.0, 1e+6)\n",
    "nBkg = RooRealVar(\"nBkg\", \"Bkg component\", entries*0.8, 1.0, 1e+6)\n",
    "\n",
    "totalPDF = RooAddPdf(\"totalPDF\", \"totalPDF\", RooArgList(sig_right, sig_left, exp_bkg), RooArgList(nSig_right, nSig_left, nBkg))\n",
    "\n",
    "r = totalPDF.fitTo(data, RooFit.Extended(ROOT.kTRUE), RooFit.Save(ROOT.kTRUE))\n",
    "\n",
    "xframe = x.frame()\n",
    "xframe.SetTitle(\"\")\n",
    "xframe.SetXTitle(\"2mu +1trk inv. mass (GeV)\")\n",
    "#totalPDF.paramOn(xframe, RooFit.Parameters(RooArgSet(meanCB, meanCB2, sigmaCB1, sigmaCB2, gamma, nSig_right, nSig_left, nBkg)), RooFit.Layout(0.2, 0.2, 0.6))\n",
    "data.plotOn(xframe)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec78975c-7aea-40a8-89c0-41d020d9b60e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Singularity kernel",
   "language": "python",
   "name": "singularity-kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
